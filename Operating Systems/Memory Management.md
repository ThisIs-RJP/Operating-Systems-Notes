
# Background

- Processes & OS share memory
- Program must be brought (from disk) into memory and placed within a process for it to be run
- Main memory and registers are the only storage  CPU can access directly
- So, memory unit only sees a stream of:
	- Addresses + read requests, or
    - Address + data and write requests
- Register access is done in one CPU clock (or less)
- Main memory can take many cycles, causing a **stall**
- **Cache** sits between main memory and CPU registers
- **Protection** of memory required to ensure correct operation

# Storage-Device Hierarchy
![[Pasted image 20240417213355.png]]

# Protection

- Need to ensure that a process can only access those addresses in its address space
- We can provide this protection by using a pair of **base** and **limit registers** define the logical address space of a process
![[Pasted image 20240417213853.png]]


# Memory Layout of a C program
![[Pasted image 20240417214348.png]]

# Hardware Address Protection

- CPU must check every memory access generated in **user mode** to be sure it is between base and limit for that user
![[Pasted image 20240417214536.png]]

- Instructions to load the **base** and **limit registers** are privileged (happen in **kernel mode**)

# Address Binding

- Address binding in operating systems refers to the process of associating a logical address (also known as a virtual address) with a physical address in memory.
	- Address binding is all about making sure that your program knows where everything is located in memory so that it can run smoothly and efficiently,

- Programs on disk, ready to be brought into memory to execute from an **input queue**
- Addresses represented in different ways at different stages of a program's life
	- Source code addresses usually symbolic
	- Compiled code addresses **bind** to **relocate** addresses
		- i.e "14 bytes from beginning of this module"
	- Linker or/loader will bind relocatable addresses to absolute addresses
		- i.e 74014
	- Each binding step maps one address space to another

# Binding of Instructions and Data to Memory

- Address binding of instructions and data to memory addresses can happen at 3 different stages
	- Compile time: If memory location known a priori, **absolute code** can be generated; must recompile code if starting location changes
	- **Load time:** Must generate **relocatable code** if memory location is not known at compile time
	- **Execution time:** **Binding** delayed until run time if the process can be moved during its execution from one memory segment to another
		- Need/Use hardware support for address maps (e.g base and limit registers)

# Logical vs Physical Address Space

- The concept of a logical address space that is bound to a separate **physical address space** is central to the proper memory management
	- **Logical address** - generated by the CPU; also referred to as **virtual address**
	- **Physical address** - address seen by the memory unit

- Logical (virtual) and physical addresses differ in execution-time address-binding scheme
- **Logical address space** is the set of all logical addresses generated by a program
- **Physical address space** is the set of all physical addresses generated by a program

# Memory Management Unit (MMU)

- There's a **Hardware device (MMU)** that at run time maps virtual (logical) to physical address
![[Pasted image 20240417220817.png]]

- Consider simple scheme which is a generalisation of the **base-register** scheme
- The base register is now called **relocation register**
- The value in the relocation register is added to every address generated by a user process at the time it is sent to memory
- The user program deals with *logical* addresses; it never sees the *real* physical addresses
	- Execution-time binding occurs when reference is made to a location in memory
	- Logical address bound to physical address

![[Pasted image 20240417221111.png]]
![[Pasted image 20240417221123.png]]

# Contiguous Allocation

-   Contiguous allocation is a memory allocation technique used by operating systems to assign memory to programs and data in a sequential, contiguous manner.

- Main memory must support both OS and user processes
- Limited resource, must allocate efficiently
- Contiguous allocation is **one early method**
- Main memory usually into two **partitions**:
	- Resident OS, usually held in low memory with **interrupt vector table**
	- User processes then held in high memory
	- Each process contained in single contiguous section of memory

- Can use relocation registers to **protect** user processes from each other, and from changing OS code and data
	- Base register contains value of smallest physical address
	- Limit register contains range of logical addresses - each logical address must be less than the limit register
	- MMU maps logical address dynamically

![[Pasted image 20240417221422.png]]

# Variable Partition

- Multiple-partition allocation
	- Degree of multiprogramming limited by number of partitions
	- **Variable-partition** sizes for efficiency (sized to a given process' needs)
	- **Hole** - block of available memory; holes of various size are scattered throughout memory
	- When a process arrives, it is allocated memory from a hole large enough to accommodate it
	- Process exiting frees its partition, adjacent free partitions combined
	- OS maintains information about:
		- A) Allocated partitions
		- B) Free partitions (hole)

# Dynamic Storage-Allocation Problem

- How to satisfy a request of size ***n*** from a list of free holes?
	- **First-fit:** Allocate the ***first*** hole that is big enough
	- **Best-fit:** Allocate the ***smallest*** hole that is big enough; must search entire list, unless ordered by size
		- Produces the smallest leftover hole
	- **Worst-fit** - Allocate the ***largest*** hole; must also search entire list
		- Produces the largest leftover hole
	- First-fit and best-fit better than worst-fit in terms of speed and storage utilisation

# Fragmentation

- **External Fragmentation** - total memory space **may** exist to satisfy a request, but it is not contiguous (**too many little pieces here and there**)
	- Approaches like **compaction** - shuffle the memory contents to put the free memory next to each other

- **Internal Fragmentation** - Allocated memory may be slightly larger than requested memory; this size difference is memory internal to a partition, but not being used (this is the case where we break memory into blocks)

# Paging

- Paging is a memory management scheme used by operating systems to efficiently manage and allocate memory. 

- The idea: Physical address space of a process can be non contiguous; process is allocated physical memory where available
	- Avoids external fragmentation
	- Avoids problem of varying sized memory chunks
- Divide physical memory into fixed-sized blocks called **frames**
	- Size is power of 2, between 512 bytes and 16 MB
- Divide logical memory into blocks of same size called **pages**
- Keep track of all free frames
- To run a program into blocks of size ***N*** pages, need to find ***N*** free frames and load program
- Set up a **page table** to translate logical to physical addresses
- **Backing store** likewise split into pages (more later)
- Can (probably will) still have internal fragmentation at %

# Address Translation Scheme

- Addresses generated by CPU is divided into:
	- **Page number (*p*)**** - used as an index into a **page table** which contains base address of each page in physical memory
	- **Page offset (*d*)**** - combined with base address to define the physical memory address that is sent to the memory unit

![[Pasted image 20240417223725.png]]

# Paging Hardware
![[Pasted image 20240417223743.png]]


# Paging Model of Logical and Physical Memory
![[Pasted image 20240417223808.png]]

# Paging - Calculating Internal Fragmentation

- We've no external fragmentation, but we still have **internal fragmentation. Why?**
- Example: Page size = 2048 bytes
- Process size = 72, 766 bytes
- 35 pages + 1086 bytes **(will need to be allocated 36 frames/pages**)
- Internal Fragmentation of 2048 - 1086 = 962 bytes
- Worst case fragmentation = 1 frame - 1 byte 
- On average fragmentation = 1/2 frame size
- So a small frame size is desirable? (what about **overhead?**)
- Smaller it gets, larger our table!
	- And each page table entry takes memory to track
- Page sizes have grown over time
	- Solaris supports two page sizes - 8KB and 4MB;

# Implementation of Page Table

- Where is the page table?

- Page table is kept in main **memory**
	- For example, registers used ( simple overview )
		- **Page table base register ( PTBR )** points to the page table
		- **Page-table length register ( PTLR )** indicates the size of the page table
- **Note... only using this scheme every data/instruction access would require two memory accesses**
	- One for the page table and one for the data/instruction
- The **two-memory access problem** can be solved by the use of a special fast-lookup hardware cache called **translation look-aside buffers (TLBS) also called associative memory** 

# Paging Hardware (no TLB)
![[Pasted image 20240417224443.png]]

# Paging Hardware with TLB

![[Pasted image 20240417224508.png]]


# Translation Look-Aside Buffer

- TLB's typically small (64 to 1024 entries)
- On a **TLB cache miss**, value is loaded into the TLB for faster access next time
	- Replacement policies must be considered (LRU, etc)
	- Some entries can be **"wired down"** for permanent fast access
- TLB's store **address-space identifiers (ASIDs)** in each process to provide address-space protection for that process 

# Hardware

- Associative memory - parallel search
	- ![[Pasted image 20240417224943.png]]
- Address translation (p, d)
	- If p is in associative register, get frame # out
	- Otherwise get frame # from page table in memory

# Effective Access Time

- **Hit ratio** - percentage of times that a page number is found in the **TLB**
- An 80% hit ratio means that we find the desired page number in the TLB 80% of the time
- Suppose it takes 10 nanoseconds to access memory
	- If we find the desired page in TLB then a mapped-memory access takes 10 ns ( disregard the small amount of time to access cache)
	- Otherwise, we need two memory accesses so it is 20 ns

- **Effective Access Time (EAT) (average)**
	- EAT = 0.8 x 10 + 0.2 x 20 = 12 nanoseconds
		*implying 20% slowdown in access time*
- Consider a more realistic hit ration of 99%
	- EAT = 0.99 x 10 + 0.01 x 20 = 10.1 ns
		*implying only 1% slowdown in access time

# Memory Protection (page tables)

- Other features: Memory protection implemented by associating protection bit with each frame to indicate if **read-only** or **read-write** and/or **execute** access is allowed
- **Valid-invalid** bit attached to each entry in the page table
	- **"valid"** indicates that the associated page is in the process' logical address space, and is thus a legal page
	- **"invalid"** indicates that the page is not in the process' logical address space/ or not in memory
- Any violations result in a trap to the kernel

# Valid (v) or Invalid (i) Bit in a Page Table
![[Pasted image 20240417225638.png]]

# Valid-Invalid Bit

- With each page table entry a valid-invalid bit is associated
	- **v** => in-memory - **memory resident**
	- **i** => not-in-memory
- Initially valid-invalid bit is set to **i** on all entries
- Example of a page table snapshot:
	- ![[Pasted image 20240417225754.png]]
- During MMU address translation, if valid-invalid bit in page table entry is **i** => page fault

# Shared Pages Example
![[Pasted image 20240417225836.png]]


# Structure of the Page Table

- Memory structures for paging can get large using straight-forward methods
	- Consider a 32 bit logical address space as on modern computers
	- Page size of 4 KB (2^12)
	- Page table would have 1 mil entries (2^20/2^12)
	- If each page is 4 bytes => each process 4 MB of physical address space for the page table alone
		- 4 MB is okay, but if larger, perhaps we don't want to allocate that **contiguously** is main memory
	- What about 48-bit address, with 4 KB (2^12) page size?
		- (2^36) = 68719476736 * 6 bytes (assuming) = 412316.860416 ... (412 GiB)
	- One simple solution is to divide the page table into smaller units, and there's a few different ways to do this:
		- Hierarchical Paging <- We can *scatter* parts of the page table across memory
		- Hashed Page Tables (other solution)
		- Inverted Page Tables (other solution)

# Hierarchical Page Tables

- Break up the logical address space into multiple page tables
- A simple technique is a two level page table
- We then page the page table
![[Pasted image 20240417230400.png]]

# Two level Paging Example

- A logical address (on 32 bit machine with 4K page) is divided into: 
	- A page number consisting of 20 bits
	- A page offset consisting of 12 bits
- Since the page tables is paged, the page number is further divided into:
	- A 10 bit page number
	- a 10 bit page offset
- Thus a logical address is as follows:
![[Pasted image 20240417230527.png]]

- Where *p1* is an index into the outer page table, and *p2* is the displacement within the page of the inner page table
- Known as **forward-mapped page table**
# Address-Translation Scheme
![[Pasted image 20240417230637.png]]

# 64 bit Logical Address Space

- Even two-level paging scheme not sufficient
- If page is 4 KB
	- Then the page table has 2^52 entries
	- If 2 level scheme, inner page tables could be 2^10 4-byte entries
	- Address would look like 
		 ![[Pasted image 20240417230743.png]]
	- Other page table has 2^42 entries or 2^44 bytes
	- One solution is to add the 2nd outer page table
	- But in the following example the 2nd outer page table is still 2^34 bytes in size
		- And 4 memory access to get to one physical memory location
			![[Pasted image 20240417230851.png]]


# Three level Paging Scheme

![[Pasted image 20240417230906.png]]

# Hashed Page Tables

- Common in Address spaces > 32 bits
- The virtual page number is hashed into a page table
	- This page table contains a chain of elements hashing to the same location
- Each element contains (1) the virtual page number (2) the value of the mapped page frame (3) a pointer to the next element
- Virtual page numbers are compared in this chain searching for a math
	- If a match is found, the corresponding physical frame is extracted

	![[Pasted image 20240417231036.png]]

# Swapping

- A process can be **swapped** temporarily out of memory to a backing store, and then brought **back** into memory for continued execution
	- Total memory space of processes can exceed physical memory
- **Backing store** - fast disk large enough to accommodate copies of all memory images for all users; must provide direct access to these memory images
- Major part of swap time is transfer time; total transfer time is directly proportional to the amount of memory swapped
- System maintains a **ready queue** of ready-to-run processes which have memory images on disk
- Does the swapped out process need to swap back into same physical addresses?
	- Depends on the address binding method
		- + consider pending I/O to / from process memory space
- Modified versions of swapping are found on many systems (i.e UNIX, Linux and Windows)
	- Swapping normally disabled
	- Started if more than threshold amount of memory allocated
	- Disabled again once memory demand reduced below threshold

# Characteristics of Various Types of Storage

![[Pasted image 20240417231252.png]]


# Virtual Memory that is Larger Than Physical Memory
![[Pasted image 20240417231318.png]]

# Schematic View of Swapping

![[Pasted image 20240417231454.png]]


# Context Switch Time including Swapping

- If next processes to be put on CPU is not in memory, need to swap out a process and swap in target process
- Context switch time can then be **very high**
- Other constraints as well on swapping
	- Pending I/O - can't swap out as I/O would occur to wrong process
	- Or always transfer I/O to kernel space, then to I/O device
- *Naive* swapping not used in modern OS
	- But modified version common
		- Swap only when free memory extremely low
- **Thrashing:** where our virtual memory is overused, and we need to keep transferring back and forth between our main memory and a backing store. "Page fault"

# Swapping with Paging
![[Pasted image 20240417231731.png]]

# Page Table when Some Pages are not in Main Memory
![[Pasted image 20240417231750.png]]